{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZXq9V27_yGH"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgtcNztk_Htr"
      },
      "source": [
        "A tiered storage system will have a hot and cold storage layer. Upon the initialization of the system, the hot layer (or cache) will be empty. This demo will show that prepopulating the cache, with randomly selected geospatial data can improve the long term performance of the system for most applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pqQpi31AXoj"
      },
      "source": [
        "**How is this storage system set up?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAlc7B3FA9th"
      },
      "source": [
        "For this experiment, there are two layers where geospatial data in the form of landsat scenes can reside: the cold storage layer and the hot storage layer. The hot storage layer is constructed as a least recently used cache."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lghT0rVBxnP"
      },
      "source": [
        "**What data is being used?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgwkeE2wB0JZ"
      },
      "source": [
        "The data that is used in this experiment are landsat scenes within the continental US. These data cannot be divided, therefore one landsat scene must reside in either the cold storage layer or the least recently used cache."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpiV3n9NDPGR"
      },
      "source": [
        "**How is data requested?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3bpOFF0DRED"
      },
      "source": [
        "Requests for data can be of three forms. A region, a state, or a county. When a request for either of these three sets is placed, the system will determine which landsat scenes encompass the request in its entirety, then move these scenes to the least recently used cache."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUlDo3RCCXY"
      },
      "source": [
        "**What is a least recently used cache?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKXWKrPCCFWK"
      },
      "source": [
        "A least recently used or LRU cache is a cache system which is based on a stack. When data are retrieved from the cache, these data are moved to the bottom of the stack. When new data are placed in the cache, these new data take the place of data at the top of the stack, which is popped off.\n",
        "\n",
        "Effectively, this means that the cache will maintain data which are frequently requested. Data which was requested the least recently is what will be removed first to make room for new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmudaGsoDJF2"
      },
      "source": [
        "# The experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YWlgQDaDK7v"
      },
      "source": [
        "The primary goal of this experiment is to determine what nuances, if any occur when the cache is empty at the start of the simulation and to provide a narrative explanation of why these nuances occur.\n",
        "\n",
        "The secondary goal of this experiment is to determine under what conditions these nuances will disappear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOTgJqFRFRYQ"
      },
      "source": [
        "To reproduce these results on your machine follow along with the accompanying steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seXmPa0UFsd7"
      },
      "source": [
        "This project uses [Poetry](https://python-poetry.org/) for dependency management. To install all necessary dependencies, follow these steps:\n",
        "\n",
        "1. Install Poetry if you haven't already:\n",
        "\n",
        "   ```bash\n",
        "   curl -sSL https://install.python-poetry.org | python3 -\n",
        "   ```\n",
        "2. Clone the repository:\n",
        "\n",
        "   ```bash\n",
        "   git clone https://github.com/your-username/Hot-Cold-Simulation.git\n",
        "   cd Hot-Cold-Simulation\n",
        "   ```\n",
        "3. Install the dependencies:\n",
        "\n",
        "   ```bash\n",
        "   poetry install\n",
        "   ```\n",
        "4. Generate the configuration files necessary to run certain portions of this project.\n",
        "\n",
        "   ```bash\n",
        "   poetry run generate-config\n",
        "   ```\n",
        "5. We will be manually adjusting the configuration files for the two different runs of our simulation. Take note of the `./config` directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJiYM5BdFtRd"
      },
      "source": [
        "# Simulation 1: Not preloading the cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWZ2ahh6HY_b"
      },
      "source": [
        "First we will run the simulation with the LRUcache empty to start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm4HhX0_GivG"
      },
      "source": [
        "1. Navigate to the `./config` directory and set the parameters as follows:\n",
        "\n",
        "```\n",
        "cache_param_increment=20\n",
        "cache_type=LRUCache\n",
        "hot_layer_constraint=310\n",
        "num_requests=100\n",
        "num_runs=8\n",
        "prepopulate_cache=False\n",
        "return_type=requests\n",
        "step_size=0.05\n",
        "```\n",
        "\n",
        "2. Now execute the simulation with the following command in your terminal\n",
        "\n",
        "```bash\n",
        "run-analysis\n",
        "```\n",
        "\n",
        "> **Note**: Increasing the `num_runs` parameter will decrease noise within your result but will take longer to execute. For a more granular view of different size caches, decrease the `cache_param_increment` parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXjxVAzxGjn5"
      },
      "source": [
        "# Simulation 2: Preloading the cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne92pN1mHdyo"
      },
      "source": [
        "Now we will prepopulate the LRUcache in its entirety with randomly selected landsat scenes at the start of the simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j13R-sWLGnXg"
      },
      "source": [
        "1. Navigate to the `./config` directory and set the parameters as follows:\n",
        "\n",
        "```\n",
        "cache_param_increment=20\n",
        "cache_type=LRUCache\n",
        "hot_layer_constraint=310\n",
        "num_requests=100\n",
        "num_runs=8\n",
        "prepopulate_cache=False\n",
        "return_type=requests\n",
        "step_size=0.05\n",
        "```\n",
        "\n",
        "2. Now execute the simulation with the following command in your terminal\n",
        "\n",
        "```bash\n",
        "run-analysis\n",
        "```\n",
        "\n",
        "> **Note**: Increasing the `num_runs` parameter will decrease noise within your result but will take longer to execute. For a more granular view of different size caches, decrease the `cache_param_increment` parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R84vtHd6Gnvd"
      },
      "source": [
        "# Results and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV5q2qXMGpgn"
      },
      "source": [
        "Under Simulation 1, the highest level of efficiency occurs with a higher proportion of larger sized requests vs smaller sized requests.\n",
        "\n",
        "![Simulation1](../_img/posts/2024-01-19/Simulation1.png)\n",
        "\n",
        "This suggests that as the simulation processes its runs and averages the results, the results are skewed to include more larger requests to maximize efficiency.\n",
        "\n",
        "This is because the cache is empty to start. The simulation wants the cache to be completely populated as soon as possible, therefore the higher proportion of larger requests will populate the cache to its maximum size more quickly.\n",
        "\n",
        "Consequently, under Simulation 2, we see that the smallest request size, in this case, counties, results in the highest level of free requests. This intuitively makes sense, as the specific data being requested is uniformly distributed. Therefore if the cache's data is skewed geographically, i.e. the cache contains one or two regions, efficiency drops.\n",
        "\n",
        "![Simulation2](../_img/posts/2024-01-19/Simulation2.png)\n",
        "\n",
        "Therefore pre-populating the cache results in the scenario where the highest level of efficiency is obtained under the request parameters most likely to occur in application. This is, when requests for data are small and random."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
