{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to dive right in? [Download Notebook](https://github.com/easierdata/EASIER-WEBSITE-V3/blob/main/notebooks/NDVI_STAC_IPFS.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this blog post, we will introduce you to a decentralized peer-to-peer hypermedia protocol called IPFS, which can revolutionize how you handle large datasets, such as satellite imagery, for tasks like object detection and land cover classification. With its content-addressing and decentralized architecture, IPFS makes it easier to share and distribute data across a network of nodes.\n",
    "\n",
    "For this post, we will be showcasing IPFS through the classic and timeless Normalized Difference Vegetation Index (NDVI) analysis of Landsat 9 imagery. This example is an excellent illustration of how IPFS can be used to handle geospatial data, from fetching imagery to publishing a geospatial analysis.\n",
    "\n",
    "So, whether you're a seasoned geospatial professional or just starting, this blog post is perfect for you. Get ready to revolutionize your geospatial analyses with IPFS!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is IPFS?\n",
    "IPFS, or InterPlanetary File System, is a peer-to-peer network protocol designed to create a decentralized and distributed web. It allows users to store and access content in a content-addressed manner, which means that the address of the content is derived from the content itself, rather than relying on a centralized server. This makes IPFS highly resilient to censorship, data loss, and other forms of centralization.\n",
    "\n",
    "In addition, IPFS is a peer-to-peer network, meaning that data is stored and shared across multiple nodes in the network. When you query the IPFS network for a piece of content, the network returns the content from the node that is closest to youÂ¹, resulting in faster data access and reduced load on any single node.\n",
    "\n",
    "In this tutorial, we will not only explore how to use IPFS to fetch Landsat imagery and publish a geospatial analysis, but we'll also be setting up our own IPFS node. This allows our computer to fetch from IPFS and, if you choose, participate in the network to make the data more available for everyone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of Using IPFS for Geospatial Workflows\n",
    "Traditionally, geospatial workflows have relied on centralized storage systems such as cloud storage providers or local file systems. However, these systems have limitations in terms of scalability, security, and availability. By contrast, IPFS provides several advantages for geospatial workflows:\n",
    "1. Content-addressing\n",
    "2. Decentralization\n",
    "3. Censorship Resistance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-addressing: \n",
    "IPFS uses content-addressing, which means that the content itself is used to derive its address. This ensures that the data is tamper-proof and verifiable, and also allows for highly efficient data retrieval."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decentralization: \n",
    "IPFS is a peer-to-peer network, which means that data is stored and shared across multiple nodes in the network. This ensures that the data is highly available and geographically distributed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Censorship Resistance:\n",
    "Data is stored and shared across multiple nodes in the network. This ensures that the data is highly available and resilient to data loss or censorship."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Calculate NDVI on Landsat 9 Imagery Using IPFS - Step-by-Step Guide\n",
    "Now that we understand the advantages of using IPFS, let's see how we can calculate NDVI on Landsat 9 imagery using IPFS in a Jupyter notebook. We will be using several libraries such as rasterio, matplotlib, and pystac_client.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "1 - [Install IPFS Kubo CLI](https://docs.ipfs.io/install/ipfs-kubo/) (if you haven't already). This will allow you to run an IPFS node on your local machine.\n",
    "\n",
    "2 - [Set up a Jupyter Notebook environment](https://www.youtube.com/watch?v=DA6ZAHBPF1U). A convenient method for achieving this is by utilizing the Jupyter integration in Visual Studio Code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize your IPFS node and start the daemon.\n",
    "This will allow you to fetch data from IPFS. You can do this by running the following commands in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ipfs version\n",
    "> ipfs version 0.10.0\n",
    "ipfs init # THis will initialize your IPFS node and create your PeerID\n",
    "ipfs daemon # This will start the IPFS daemon. Leave this running in the background."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Libraries\n",
    "First, we need to install the required libraries. I reccomend using a virtual environment to install the Python libraries. Here is the [requirements.txt](requirements.txt) file I used for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run this in the terminal to install the required packages.\n",
    "python3 -m venv venv # create virtual environment\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from io import BytesIO\n",
    "\n",
    "# Third-party library imports\n",
    "import geopandas as gpd\n",
    "from matplotlib import colors, colormaps\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.parser import isoparse\n",
    "from PIL import Image as pil_image\n",
    "from ipfs_stac import client\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiaize Web3 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello worlds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_client = client.Web3(stac_endpoint=\"http://ec2-54-172-212-55.compute-1.amazonaws.com/api/v1/pgstac/\", local_gateway=\"127.0.0.1\")\n",
    "data = my_client.getFromCID(\"QmZ4tDuvesekSs4qM5ZBKpXiZGun7S2CYtEZRB3DYXkjGx\")\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did we set up the STAC API?\n",
    "Before we continue with the steps to connect to the STAC API and search for Landsat 9 imagery from the Washington D.C. area, it's worth mentioning that we have set up a STAC server ourselves and populated it with IPFS CIDs for the Landsat 9 dataset. As a proof of concept, there are only 5 landsat scenes currently on the STAC server. To learn more about the technique we used for this process, you can refer to this blog post: [A New Way to Reference and Retrieve Geographic Data](https://easierdata.org/updates/2022/2022-12-02-a-new-way-to-reference-and-retrieve-geographic-data).\n",
    "\n",
    "If you're interested in setting up your own STAC server and populating it with IPFS CIDs, you can follow the steps outlined in our [stac-fastapi GitHub repository fork](https://github.com/easierdata/stac-fastapi).\n",
    "\n",
    "With that background, let's continue with connecting to our STAC API and searching for Landsat 9 imagery from the Washington D.C. area:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore our STAC Catalog with GeoPandas and the ipfs-stac packages\n",
    "For demo purposes, we have populated the STAC server with a small subset of Landsat 9 imagery. In order to effortless work with STAC and IPFs, our team has developed the [ipfs-stac](https://github.com/easierdata/ipfs-stac) package which is included in the requirements.txt file.\n",
    "\n",
    "Before running the following code cells, ensure you have started the IPFS daemon by either using the IPFS desktop application or running `ipfs daemon` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [-76.964657, 38.978967, -76.928008, 39.002783] \n",
    "items = my_client.searchSTACByBox(bbox,\"landsat-c2l1\")\n",
    "\n",
    "\n",
    "df = gpd.GeoDataFrame.from_features(items.to_dict(), crs=\"epsg:4326\")\n",
    "\n",
    "df.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Landsat Scene from Washington D.C. Area (Or somewhere else!)\n",
    "The following code connects to our STAC API instance and searches for Landsat 9 imagery by submitting a bounding box query to the STAC server. The STAC server returns a list of Landsat 9 scenes that intersect with the bounding box. Our STAC server only has ~10 scenes, so most bounding boxes will only return a single scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This satellite image was taken by the LANDSAT_9 platform on Wed Feb  2 09:53:39 2022. \n",
      "The image covers an area with a bounding box of [10.722394904433058, 40.69369269987787, 13.472045876637816, 42.80903201136925]. \n",
      "The image has a resolution of [8031, 7931] pixels and uses the EPSG:32633 coordinate reference system. \n",
      "The percentage of cloud cover in the image is 2.4% over the entire image.\n"
     ]
    }
   ],
   "source": [
    "# Washington, DC\n",
    "#bbox = [-76.964657, 38.978967, -76.928008, 39.002783] \n",
    "\n",
    "# Taj Mahal, India\n",
    "# bbox = [78.039957, 27.164888, 78.045247, 27.175254]\n",
    "\n",
    "# Christ the Redeemer, Rio de Janeiro, Brazil\n",
    "# bbox = [-43.210297, -22.951625, -43.207670, -22.948875]\n",
    "\n",
    "# Great Wall Of China (Note: The wall is more than 13,000 miles long, and the bounding box only covers a small portion of it. Here's a bounding box for the Badaling section near Beijing)\n",
    "#bbox = [116.056298, 40.338204, 116.058715, 40.343322]\n",
    "\n",
    "# Petra, Jordan\n",
    "# bbox = [35.442749, 30.322058, 35.472730, 30.342304]\n",
    "\n",
    "# Machu Picchu, Peru\n",
    "# bbox = [-72.544959, -13.165088, -72.530122, -13.155547]\n",
    "\n",
    "# Chichen Itza, Mexico\n",
    "# bbox = [-88.570015, 20.682207, -88.568230, 20.684936]\n",
    "\n",
    "# Colosseum, Rome, Italy\n",
    "bbox = [12.490827, 41.889249, 12.494162, 41.891876]\n",
    "\n",
    "\n",
    "item = my_client.searchSTACByBox(bbox, \"landsat-c2l1\")[0]\n",
    "properties = item.properties\n",
    "print(f\"This satellite image was taken by the {properties['platform']} platform on {isoparse(properties['datetime']):%c}. \\n\\\n",
    "The image covers an area with a bounding box of {item.bbox}. \\n\\\n",
    "The image has a resolution of {properties['proj:shape']} pixels and uses the EPSG:{properties['proj:epsg']} coordinate reference system. \\n\\\n",
    "The percentage of cloud cover in the image is {properties['eo:cloud_cover']}% over the entire image.\")\n",
    "# Uncomment the line below to see the full metadata for the item\n",
    "#item "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch bands 4 and 5 from IPFS (Red and NIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching QmXyXkdvj7spdfyFTtdq6PGHo7QFK8YcJCQHeJC88CXwHa\n",
      "Fetching QmcD4krqqBEN2KCtdebeUP9VQXjKxu9mJbDo8retBjbDEV\n",
      "Red band CID: QmXyXkdvj7spdfyFTtdq6PGHo7QFK8YcJCQHeJC88CXwHa\n",
      "NIR band CID: QmcD4krqqBEN2KCtdebeUP9VQXjKxu9mJbDo8retBjbDEV\n"
     ]
    }
   ],
   "source": [
    "red_band = my_client.getAssetFromItem(item, \"red\")\n",
    "nir_band = my_client.getAssetFromItem(item, \"nir08\")\n",
    "\n",
    "print(f\"Red band CID: {red_band}\")\n",
    "print(f\"NIR band CID: {nir_band}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Assets from IPFS and transform the image an NP array\n",
    "This could take awhile depending on your internet connection and the number of IPFS peers you are connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid path or file: <ipfs_stac.client.Asset object at 0x135a03510>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m red_band_np \u001b[39m=\u001b[39m red_band\u001b[39m.\u001b[39;49mto_np_ndarray()\n\u001b[1;32m      2\u001b[0m nir_band_np \u001b[39m=\u001b[39m nir_band\u001b[39m.\u001b[39mto_np_ndarray()\n",
      "File \u001b[0;32m~/Documents/code/EASIER-WEBSITE-V3/.venv/lib/python3.11/site-packages/ipfs_stac/client.py:22\u001b[0m, in \u001b[0;36mensure_data_fetched.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mData for asset has not been fetched yet. Fetching now...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetch()\n\u001b[0;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/code/EASIER-WEBSITE-V3/.venv/lib/python3.11/site-packages/ipfs_stac/client.py:265\u001b[0m, in \u001b[0;36mAsset.to_np_ndarray\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m@ensure_data_fetched\u001b[39m\n\u001b[1;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_np_ndarray\u001b[39m(\u001b[39mself\u001b[39m, dtype: np\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata) \u001b[39mas\u001b[39;00m dataset:\n\u001b[1;32m    266\u001b[0m         \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mread(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m~/Documents/code/EASIER-WEBSITE-V3/.venv/lib/python3.11/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Documents/code/EASIER-WEBSITE-V3/.venv/lib/python3.11/site-packages/rasterio/__init__.py:216\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(fp, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m         \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(fp, (os\u001b[39m.\u001b[39mPathLike, MemoryFile, FilePath))\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minvalid path or file: \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(fp))\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minvalid mode: \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(mode))\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid path or file: <ipfs_stac.client.Asset object at 0x135a03510>"
     ]
    }
   ],
   "source": [
    "red_band_np = red_band.to_np_ndarray()\n",
    "nir_band_np = nir_band.to_np_ndarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NDVI\n",
    "Now, we can calculate the NDVI using the loaded numpy arrays. The forumula we are using for NDVI is straight from the [USGS website](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-normalized-difference-vegetation-index?qt-science_support_page_related_con=0#qt-science_support_page_related_con). We will also add a small value to the denominator to avoid divide by zero errors because there is a chance that the red and NIR bands will have the same value in a given pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.0001 # Avoid divide by zero errors\n",
    "ndvi = (nir_band_np - red_band_np) / (nir_band_np + red_band_np + eps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NDVI\n",
    "With the NDVI calculated, we can plot the NDVI image using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Remove the axes\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Set the color map to the min and max values of NDVI\n",
    "ndvi_min, ndvi_max = np.min(ndvi), np.max(ndvi)\n",
    "norm = colors.Normalize(vmin=ndvi_min, vmax=ndvi_max)\n",
    "\n",
    "# Use the normalization object for the image and the color map\n",
    "green_color_map = colormaps[\"Greens\"]\n",
    "green_ndvi = green_color_map(norm(ndvi))\n",
    "\n",
    "img = ax.imshow(green_ndvi)\n",
    "ax.set_title(\"NDVI Plot\")\n",
    "\n",
    "cax = fig.add_axes([0.9, 0.15, 0.03, 0.7])\n",
    "cb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=green_color_map), cax=cax, orientation='vertical')\n",
    "cb.set_label(\"NDVI\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add plot image to IPFS\n",
    "Now, let's add the plot to our local IPFS node! In order to do that, we need to save this plot as bytes and then we can use `myclient_add_bytes_to_ipfs` to add the bytes to IPFS. This function will return the IPFS CID for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_to_buffer(plot: plt.Figure) -> bytes:\n",
    "    buffer = BytesIO()\n",
    "    plot.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "plot_buffer = save_plot_to_buffer(fig)\n",
    "plot_cid = my_client.uploadToIPFS(plot_buffer) # Need a function to add to IPFS, not Pin to IPFS\n",
    "print(f\"Plot CID: {plot_cid}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch plot image from IPFS and display it\n",
    "Now that we have the plot saved to IPFS, we can fetch it from our local node using the CID hash. We can then display the image using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_png = my_client.getFromCID(plot_cid)\n",
    "img = pil_image.open(BytesIO(plot_png)) # Open to changing this if the getFromCID function returns a PIL image\n",
    "display(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this blog post, we demonstrated how to calculate NDVI on Landsat 9 imagery using IPFS in a Jupyter notebook. By leveraging IPFS in place of traditional storage systems, we can benefit from content-addressing and decentralization. These features lead to faster data access, improved data persistence, and more efficient storage, highlighting the potential of IPFS in geospatial workflows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Want to make the data even more accessible?\n",
    "If you would like to make the dataset we used in this tutorial more accessible, you can add the two landsat bands to your IPFS node as well. This will allow others to fetch the data from your IPFS node, which will improve the availability of the data. After pinning the data to our local IPFS node, we can fetch it from any IPFS node worldwide using the same commands as before. However, keep in mind that download speeds will be influenced by the distance between your computer and the requester's location, as well as the internet connection speeds for both parties.\n",
    "\n",
    "\n",
    "To do this, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_band.pin()\n",
    "nir_band.pin()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `client.list_pinned()` command to confirm that the two Landsat bands and the plot have been added to your IPFS node. By pinning the data, you have made it accessible to the IPFS network, allowing others to access it as well. By sharing this data on IPFS, you are contributing to the open and decentralized web, and making it easier for others to access and use this data. Perhaps the next person following this tutorial will obtain the data from your IPFS node!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_client.list_pinned()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes\n",
    "Â¹ The IPFS node may not actually be the closest node to you. But is simply the one that is most capable of serving the data. This is because IPFS nodes are not required to be online 24/7 and have various levels of bandwidth and storage capacity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
