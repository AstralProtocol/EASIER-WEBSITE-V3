{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Front page blurb\n",
    "\n",
    "Measuring the impact of deforestation is one of the many overarching goals of the [Global Ecosystem Dynamics Investigation](https://gedi.umd.edu/mission/mission-overview/) (GEDI) project. With support of the GEDI's [LIDAR system](https://gedi.umd.edu/mission/technology/) and hitching a ride on the International Space Station, high-quality laser ranging observations collect a 3D structure of the Earths forests for which can be used to estimate the height of forests, the density of vegetation, and providing detail on the Earths carbon cycle. In this blog post, we will  explore the GEDI dataset by leveraging IPFS with the ipfs-stac python library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A common thread with geospatial data is its visual nature. But visualization isn’t just limited to imagery—any dataset with a geospatial component can be transformed into a visual format, making complex information easier to grasp. One such format that we'll be exploring today is the [Hierarchical Data Format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) (HDF5), a scalable and flexible format to store a variety of data types and structures, including multidimensional arrays, tables and metadata.\n",
    "\n",
    "To provide a sense of how much data GEDI collected, each laser on the lidar system fired off 242 times each second, bouncing off the surface with a 25-meter diameter footprint. Around 16 billion laser pulses per year were continuously collected and an estimated 10 billion cloud-free observations were produced during the 24 month mission. The derived data products in total are ~300TB in size.\n",
    "\n",
    "```\n",
    "\"Existing pan-tropical biomass maps use laser data acquired nearly 15 years ago and were based on less than 5 million laser observations in total. GEDI collects 6 million laser observations every day. So over the tropics, we've already collected about two orders of magnitude more data than what was ‘state-of-the-art' before.\"\n",
    "\n",
    "```\n",
    "\n",
    " -- Ralph Dubayah, [GEDI Principal Investigator](https://www.nasa.gov/centers-and-facilities/goddard/nasa-forest-structure-mission-releases-first-data/) and professor of geographical sciences at the UMD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving GEDI data from IPFS\n",
    "\n",
    "We'll be exploring the [GEDI L4A](https://cmr.earthdata.nasa.gov/search/concepts/C2237824918-ORNL_CLOUD.html) collection, a data product that's been processed and converted to footprint estimates of above ground biomass density. Let's dive in and see how we can retrieve this data from IPFS using python!\n",
    "\n",
    "### Preqrequisites\n",
    "\n",
    "1. Install the [IPFS desktop app](https://docs.ipfs.tech/install/ipfs-desktop/#install-instructions) or [Kubo CLI client](https://docs.ipfs.tech/install/command-line/) as this will will allow you to start up a IPFS local node on your machine.\n",
    "\n",
    "\n",
    "2. Python that's version `3.10.x` or higher as to install our dependencies such as [ipfs-stac](https://pypi.org/project/ipfs-stac/) and [Jupyter Notebook](https://jupyter.org/install#jupyter-notebook).\n",
    "\n",
    "To get started, save the [libraries](ADD LINK) we'll be using as a text file named `requirements.txt`. I also recommend creating a virtual environment by running the following commands in the terminal.\n",
    "\n",
    "``` bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Next, start up Jupyter Notebook session by with the following command.\n",
    "\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "and create a new notebook by clicking on the `New` button and selecting `Python 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from ipfs_stac import client\n",
    "import json\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our client object\n",
    "\n",
    "The `ipfs-stac` library is how we'll be interacting the [Easier STAC API](https://stac.easierdata.info) and communicating with the IPFS network via the [Kubo RPC API](https://docs.ipfs.tech/reference/kubo/rpc/). Below are the properties that we can pass in along with the default assigned values to establish this connection.\n",
    "\n",
    "A feature that's been added to the `ipfs-stac` library is the ability to start the daemon if it's not already running. We perform this check as the `client` object is initialized.\n",
    "\n",
    "Let's see what collections are available to us by via our client object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easier_client = client.Web3(\n",
    "    local_gateway=\"127.0.0.1\",\n",
    "    gateway_port=\"8081\",\n",
    "    api_port=\"5001\",\n",
    "    stac_endpoint=\"https://stac.easierdata.info\",\n",
    ")\n",
    "\n",
    "easier_client.collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the [Landsat 9 imagery](https://easierdata.org/notebooks/ndvi_stac_ipfs#How-did-we-set-up-the-STAC-API?), we've also prepared a sample set of GEDI data, commonly referred to as **\"granules\"**.\n",
    "\n",
    "Let's see how many granules are in the collection id  `GEDI_L4A_AGB_Density_V2_1_2056.v2.1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"GEDI_L4A_AGB_Density_V2_1_2056.v2.1\"\n",
    "items = easier_client.searchSTAC(collections=[collection_id])\n",
    "print(f\"The {collection_id} collection has {len(items)} items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a geojson from IPFS and display it in a map\n",
    "\n",
    "`harvard.json\n",
    " bafkreib5tmwa7qb2qnm2zqgklsnesjlt4w7uxwbqvbqz7se54t7kxceuu4\n",
    " `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_cid = \"bafkreib5tmwa7qb2qnm2zqgklsnesjlt4w7uxwbqvbqz7se54t7kxceuu4\"\n",
    "geojson_result = easier_client.getFromCID(geojson_cid)\n",
    "\n",
    "# Convert to json object as to be able to read it with geopandas\n",
    "geojson = json.loads(geojson_result)\n",
    "geojson_layer = gpd.GeoDataFrame.from_features(geojson[\"features\"], crs=\"epsg:4326\")\n",
    "\n",
    "# Create the map centered on the bounds of the first GeoJSON layer\n",
    "m = folium.Map(scrollWheelZoom=False)\n",
    "bounds = geojson_layer.total_bounds\n",
    "m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]])\n",
    "\n",
    "# Add the first layer manually using GeoJson\n",
    "harvard_forests = folium.GeoJson(\n",
    "    data=geojson,\n",
    "    name=\"Geojson from IPFS\",\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": \"blue\",\n",
    "        \"color\": \"blue\",\n",
    "        \"weight\": 2,\n",
    "        \"fillOpacity\": 0.5,\n",
    "    },\n",
    ")\n",
    "\n",
    "harvard_forests.add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we'll query the granules that intersect the geojson that was retrieved from IPFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query content from STAC server and process it\n",
    "granules = easier_client.searchSTAC(\n",
    "    intersects=geojson[\"features\"][0][\"geometry\"], collections=[collection_id]\n",
    ")\n",
    "\n",
    "print(f\"Found {len(granules)} granules that intersect the geojson\")\n",
    "granules_dict = [granule.to_dict() for granule in granules]\n",
    "granules_geojson = {\"type\": \"FeatureCollection\", \"features\": granules_dict}\n",
    "\n",
    "# Add as a layer to the map\n",
    "granules_layer = folium.GeoJson(\n",
    "    data=granules_geojson,\n",
    "    name=\"Granules\",\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": \"red\",  # Orange fill color\n",
    "        \"color\": \"black\",  # Orange border color\n",
    "        \"weight\": 5,  # Border width\n",
    "        \"opacity\": 0.1,  # Border opacity\n",
    "        \"fillOpacity\": 0.01,  # Fill opacity\n",
    "    },\n",
    ")\n",
    "\n",
    "granules_layer.add_to(m)\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
